% Clear workspace
clc
clear
%-----------------Read pos/Nng words from dictianary------------------
% Read in all of the positive words
fidPositive = fopen(fullfile('opinion-lexicon-English','positive-words.txt'));
% leave out all of the comments in the text file
C = textscan(fidPositive,'%s','CommentStyle',';');
% convert the cell array 'C' to a string
wordsPositive = string(C{1});
% close all files
fclose all;

% Read in all of the negative words
fidNegative = fopen(fullfile('opinion-lexicon-English','negative-words.txt'));
% leave out all of the comments in the text file
C = textscan(fidNegative,'%s','CommentStyle',';');
% convert the cell array 'C' to a string
wordsNegative = string(C{1});
% close all files
fclose all;

% create hash table
words_hash = java.util.Hashtable; 
% Put all positive words in the hash-table
[possize, ~] = size(wordsPositive); 
for ii = 1:possize
 words_hash.put(wordsPositive(ii,1),1);
end
% Put all Negative words in the hash-table
[negsize, ~] = size(wordsNegative); 
for ii = 1:negsize
 words_hash.put(wordsNegative(ii,1),-1);
end

%-------------------Collect review data from file---------------------
%filename = "yelp_labelled.txt";
%filename = "imdb_labelled_2.txt"; 
filename = "twitter_mvom.txt";

dataReviews = readtable(filename,'TextType','string'); 
% get just the review text
textData = dataReviews.review;
% get just the human reviewer's sentiment scores
actualScore = dataReviews.score; 
sents = preprocessReviews(textData);
fprintf('File: %s, Sentences: %d \n', filename, size(sents)); 

%---------------------Sentiment Scores-----------------------
sentimentScore = zeros(size(sents));

% for each sentence in the text data
for ii = 1 : sents.length
    % get the preprocessed words
    docwords = sents(ii).Vocabulary;
    % for each word in the sentence
    for jj = 1 : length(docwords)
        % if the word is in the dictionary
        if words_hash.containsKey(docwords(jj))
            % get the sentiment score of the word and add it to the total
            % sentiment score of the tweet
            sentimentScore(ii) = sentimentScore(ii) + words_hash.get(docwords(jj));
        end
    end

    % normalise the sentiment score so -1 is given for negative Sentiments
    % and 1 for positive sentiments
    if (sentimentScore(ii)>=1)
        sentimentScore(ii)=1; 
    elseif (sentimentScore(ii)<=-1)
        sentimentScore(ii) = -1; 
    end
    fprintf('Sent: %d, words: %s, FoundScore: %d, GoldScore: %d\n',...
        ii, joinWords(sents(ii)), sentimentScore(ii), actualScore(ii)); 
end

%-----------------Results and Confusion matrix-------------------
% Find the number of all sentimentScore equal to 0: either not found or neutral
ZeroVal = sum(sentimentScore == 0);
% Find all 'distinct' values (either -1 or 1) 
covered = numel(sentimentScore) - ZeroVal;
fprintf("Total of positive and negative classes (coverage): %2.2f%%, Distinct %d, Not Found or Neutral: %d\n",...
    (covered * 100)/numel(sentimentScore), covered, ZeroVal); 

% calculate true positive 
tp = sentimentScore((sentimentScore==1) & ( actualScore==1));
% calculate true negative 
tn = sentimentScore((sentimentScore==-1) & ( actualScore==0));

% Calculate accuracy
acc = (numel(tp) + numel(tn))*100/covered;
fprintf("Accuracy: %2.2f%%, TP: %d, TN: %d\n", acc, numel(tp), numel(tn)); 

% Generate confusion matrix of the results
figure
confusionchart(actualScore, sentimentScore);




